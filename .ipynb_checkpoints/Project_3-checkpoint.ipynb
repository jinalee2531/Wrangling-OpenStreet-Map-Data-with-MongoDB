{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3: Wrangle OpenStreetMap Data\n",
    "\n",
    "\n",
    "This project extracted and cleaned OpenStreetMap data(https://en.wikipedia.org/wiki/OpenStreetMap) and stored it into MongoDB so that users can explore quality data fast.\n",
    "OpenStreetMap is map information in a topological data structure collected by volunteers. It consists of four major elements; Node, Ways, Relation and Tags. Nodes present geographic information of specified locations by points and create log such as user, update time etc. Ways represent linear features such as areas, rivers, streets and create log such as user, update time etc. Relations are representing relationship between Nodes and Ways, and Tags contains metadata of its Nodes or Ways elements.\n",
    "I used OpenStreetMap New York area of OSM file downloaded from MapZen (https://mapzen.com/data/metro-extracts/). Its size is about 737,545kb and it contains 3,449,666 elements consists of 2,961,075 'node's, 2571 'relation's, and 486020 'way' tags.\n",
    "Assessing and improving data quality, this project considered validity, accuracy, completeness, consistency, and uniformity of data. The whole process of project are as below:\n",
    "\n",
    "\n",
    "\n",
    "## 1 Auditing Data\n",
    "First, this project audited the data's quality in five perspectives to assure concrete data analysis result.\n",
    "     * Completeness\n",
    "   : Computing descriptive statistics of data\n",
    "     - Number of elements\n",
    "     - Counted number of records for each attribute and missing values.     \n",
    "     * Validity\n",
    "       : Audited if street name, postcode, height data are in appreciate formats.         \n",
    "     * Accuracy\n",
    "       : Checked if postcode starts with New York's code: 0 or 1.     \n",
    "     * Consistency\n",
    "       : Not applicable here since, this project use data from only one source.     \n",
    "     * Uniformity\n",
    "       : Checked 'height' if it is in the same unit, and corrected data in different units to foot.\n",
    "\n",
    " \n",
    "## 2 Reshaping Data\n",
    "Designed the shape of data, reflecting attribute types revealed through auditing.\n",
    "     * Filtering out attributes that have non-character name.     \n",
    "     * Grouped related attributes\n",
    "        - created: to data creation information in a dictionary such as user, timestamp, etc.\n",
    "        - address: grouped attributes under 'Address' such as addr:housenumber, addr:zipcode etc.\n",
    "        - others which has sub-categories : grouped attributes that its names contains ':', for example, 'gins:housenumber.'     \n",
    "     * Combining 'latitude' value and 'longtitude' value into a list 'pos' for using GEO2D index in MongoDB     \n",
    "     * Transformed data type of timestamp from string to datetime object.\n",
    "\n",
    "     \n",
    "## 3 Imported Data to MongoDB \n",
    "Transformed in JSON File and created indexes of fields which are used for queries later.\n",
    "    \n",
    "## 4 Run Queries\n",
    "Ran queries to answer these questions.\n",
    "    * Question 1: Top 10 users who uploaded the data most often and frequency\n",
    "    * Question 2: The number of data uploaded by year.\n",
    "    * Question 3: Finding the five nearest locations from \"AJ's Pizza\".\n",
    "    \n",
    "## 5 Conclusion\n",
    "This project focused on improving data of major attributes, which are occupying more than 80% of data, and worked well enough to answer arisen questions in the project.\n",
    "However, there are still hundreds of field not cleaned yet. Especially, attributes that have sub categories such as gnis, tiger, cityrack seemed to have overlapping with other attributes. If we are given more time and enough information about these categories, we might try to improve the quality of data by cross-checking values of each attribute and integrating related attributes as many as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Auditing\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import re\n",
    "from  collections import defaultdict\n",
    "import pprint\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "from bson import json_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_to_dict(dic, dic_key, key_to_cnt):\n",
    "    \"\"\"Updating/initiating value for each attributes in the data.\"\"\"\n",
    "    \n",
    "    updated_dic = dic\n",
    "    try    : updated_dic[dic_key][key_to_cnt] +=1\n",
    "    except : updated_dic[dic_key][key_to_cnt] = 1\n",
    "    return updated_dic\n",
    "\n",
    "def print_sorted_dict(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print \"%s: %d\" % (k, v)\n",
    "        \n",
    "def stats_data(osm_file_name_input, pretty = False, tags = ('node', 'way', 'relation')):\n",
    "    problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "    lower = re.compile(r'^([a-z]|_)*$')\n",
    "    lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "    \n",
    "    \n",
    "    data=defaultdict(dict)\n",
    "    errors=defaultdict(dict)\n",
    "    \n",
    "    stats = dict(tags_count = {}\n",
    "                 , attrib_count={}\n",
    "                 , tag_attrib_count={}\n",
    "                 , non_chars_count ={}\n",
    "                 , subgroups = {}\n",
    "                )   \n",
    "    \n",
    "    context = iter(ET.iterparse(osm_file_name_input, events = ('start','end')))\n",
    "    _, root = next(context)\n",
    "    \n",
    "    i=0\n",
    "    for event, element in context:\n",
    "        \n",
    "        if event !='end' or element.tag not in tags:\n",
    "            continue\n",
    "        \n",
    "        i+=1\n",
    "        if i%100000 ==1:\n",
    "            print i           \n",
    "        \n",
    "        element_dict={}   \n",
    "        element_dict['tag_type'] = element.tag\n",
    "\n",
    "        stats = add_to_dict(dic = stats, dic_key='tags_count', key_to_cnt=element.tag)\n",
    "         ### exploring top level attributes\n",
    "        for attr in element.attrib:\n",
    "            key = attr\n",
    "            val = element.attrib[key]            \n",
    "            element_dict[key] = val         \n",
    "            stats = add_to_dict(dic = stats, dic_key='attrib_count', key_to_cnt= key)\n",
    "        \n",
    "        id_ = element_dict['id']\n",
    "        # print '1: ',element_dict\n",
    "        \n",
    "        #### exploring low level attributes\n",
    "        for nested in element:\n",
    "            try:\n",
    "                key = nested.attrib['k']\n",
    "                val = nested.attrib['v']\n",
    "                if val==\"{}\": print \"none ; \",val\n",
    "                \n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            ## collecting keys and its values if the key is containing punctuations\n",
    "            if key.startswith('cityracks'):\n",
    "                key = \":\".join(key.split('.'))\n",
    "            \n",
    "            if problemchars.search(key) :\n",
    "                try:\n",
    "                    stats['non_chars_count'][key].append(val)\n",
    "                except KeyError:\n",
    "                    stats['non_chars_count'][key]=[val]              \n",
    "                    \n",
    "            ## grouping attributes that have sub attributes\n",
    "            \n",
    "            elif len(key.split(':'))>=2:\n",
    "                splited = key.split(':')\n",
    "                group_key = splited[0]\n",
    "                sub_group_key = \":\".join(splited[1:])\n",
    "                 \n",
    "                if group_key not in element_dict.keys():\n",
    "                    element_dict[group_key]= defaultdict(dict) \n",
    "                \n",
    "                try:\n",
    "                    element_dict[group_key][sub_group_key]=val\n",
    "                except :\n",
    "                    if key not in errors[element_dict['id']].keys():\n",
    "                        errors[element_dict['id']]={key:[val]}\n",
    "                    else :\n",
    "                        errors[element_dict['id']][key].append(val)\n",
    "                \n",
    "                if group_key not in stats['subgroups'].keys():\n",
    "                    stats['subgroups'][group_key]={sub_group_key:1}\n",
    "                sub = stats['subgroups'][group_key]\n",
    "                try :\n",
    "                    sub[sub_group_key] +=1\n",
    "                except KeyError:\n",
    "                    sub[sub_group_key] =1\n",
    "\n",
    "            else :\n",
    "                element_dict[key] = val                \n",
    "                stats = add_to_dict(dic = stats, dic_key='tag_attrib_count', key_to_cnt= key)\n",
    "            \n",
    "        \n",
    "        data[id_] = element_dict\n",
    "        \n",
    "        root.clear()\n",
    "\n",
    "        \n",
    "    return data, stats, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OSM_FILE_NAME = 'new_new-york_new-york'\n",
    "OSM_FILE = os.path.join('data',OSM_FILE_NAME+\".osm\")\n",
    "SAMPLE_FILE_NAME ='mini_sample_new-york_new-york' \n",
    "SAMPLE_FILE =os.path.join('data',SAMPLE_FILE_NAME+\".osm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    osm_file_name =OSM_FILE_NAME\n",
    "    osm_file= OSM_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    osm_file_name =SAMPLE_FILE_NAME\n",
    "    osm_file= SAMPLE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "data, stats, errors  = stats_data(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attrib_count': {'changeset': 8450,\n",
      "                  'id': 8450,\n",
      "                  'lat': 8450,\n",
      "                  'lon': 8450,\n",
      "                  'timestamp': 8450,\n",
      "                  'uid': 8450,\n",
      "                  'user': 8450,\n",
      "                  'version': 8450},\n",
      " 'non_chars_count': {},\n",
      " 'subgroups': {'addr': {'city': 6,\n",
      "                        'country': 4,\n",
      "                        'housenumber': 130,\n",
      "                        'postcode': 125,\n",
      "                        'state': 6,\n",
      "                        'street': 127},\n",
      "               'cityracks': {'housenum': 4,\n",
      "                             'installed': 2,\n",
      "                             'large': 5,\n",
      "                             'rackid': 4,\n",
      "                             'small': 4,\n",
      "                             'street': 4},\n",
      "               'gnis': {'Class': 2,\n",
      "                        'County': 2,\n",
      "                        'County_num': 2,\n",
      "                        'ST_alpha': 2,\n",
      "                        'ST_num': 2,\n",
      "                        'county_id': 10,\n",
      "                        'county_name': 2,\n",
      "                        'created': 10,\n",
      "                        'feature_id': 12,\n",
      "                        'id': 3,\n",
      "                        'import_uuid': 1,\n",
      "                        'reviewed': 1,\n",
      "                        'state_id': 10},\n",
      "               'internet_access': {'fee': 2}},\n",
      " 'tag_attrib_count': {'access': 1,\n",
      "                      'amenity': 15,\n",
      "                      'artwork_type': 1,\n",
      "                      'barrier': 3,\n",
      "                      'building': 2,\n",
      "                      'capacity': 4,\n",
      "                      'created_by': 97,\n",
      "                      'crossing': 1,\n",
      "                      'denomination': 2,\n",
      "                      'denotation': 1,\n",
      "                      'ele': 14,\n",
      "                      'height': 2,\n",
      "                      'highway': 16,\n",
      "                      'historic': 1,\n",
      "                      'import_uuid': 2,\n",
      "                      'internet_access': 1,\n",
      "                      'is_in': 2,\n",
      "                      'leaf_type': 1,\n",
      "                      'leisure': 4,\n",
      "                      'man_made': 2,\n",
      "                      'name': 28,\n",
      "                      'natural': 8,\n",
      "                      'network': 1,\n",
      "                      'note': 1,\n",
      "                      'opening_hours': 1,\n",
      "                      'phone': 3,\n",
      "                      'place': 2,\n",
      "                      'power': 10,\n",
      "                      'railway': 4,\n",
      "                      'ref': 1,\n",
      "                      'religion': 4,\n",
      "                      'second_hand': 1,\n",
      "                      'shop': 6,\n",
      "                      'source': 5,\n",
      "                      'start_date': 1,\n",
      "                      'traffic_signals': 1,\n",
      "                      'type': 1,\n",
      "                      'usage': 1,\n",
      "                      'website': 3,\n",
      "                      'wheelchair': 1,\n",
      "                      'wikipedia': 3},\n",
      " 'tags_count': {'node': 8450}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shop', 'man_made', 'height', 'leaf_type', 'is_in', 'access', 'capacity', 'barrier', 'religion', 'opening_hours', 'wikipedia', 'note', 'source', 'usage', 'denotation', 'artwork_type', 'ref', 'start_date', 'website', 'power', 'import_uuid', 'leisure', 'denomination', 'phone', 'historic', 'network', 'building', 'natural', 'type', 'wheelchair', 'traffic_signals', 'place', 'second_hand', 'crossing', 'railway', 'internet_access']\n"
     ]
    }
   ],
   "source": [
    "### creating a list of attributes to exclude: attributes that have less than 10 values.\n",
    "tag_attrib_to_exclude=[key for key, val in stats['tag_attrib_count'].items() if val<=10]\n",
    "print tag_attrib_to_exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "#added 'created_by' attribute of low level elements\n",
    "CREATED.append('created_by')\n",
    "\n",
    "\"\"\"\n",
    "### street name : street type in expected\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", 'Turnpike',\n",
    "            \"Trail\", \"Parkway\", \"Commons\",'Way','Bayside', 'Circle', 'Highway', 'West', 'South','East', 'North'\n",
    "            ,'Plaza','Cove', 'Bowery', 'Concourse', 'Park', 'Terrace','Walk','Loop', 'Broadway', 'Oval', 'Crescent']\n",
    "\n",
    "### pair of street types to fix and to correct street types\n",
    "to_fix={'way':'Way', 'rd':'Road', 'avenue':'Avenue', 'st':'Street', 'ave':'Avenue', 'avene':'Avenue'\n",
    "       , 'tpke':'Turnpike'}\n",
    "\n",
    "# postcode starts with 0 or 1 in NY\n",
    "postcode_type_re = re.compile('[0-9]{5}(?:-[0-9]{4})?$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_timestamp(str_time):                              \n",
    "    \"\"\"\n",
    "    Recording inappropriate date type in 'caution' dictionary and transforming timestamp in datetime object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        time = datetime.strptime(str_time, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    except:\n",
    "        cautions['timestamp'].append(str_time)\n",
    "        time=str_time\n",
    "    return time\n",
    "\n",
    "def audit_street(street_name, id_):\n",
    "    \"\"\"\n",
    "    Recording inappropriate street_type in 'caution' dictionary and returns it corrected.\n",
    "    \"\"\"\n",
    "    \n",
    "    street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "    try: \n",
    "        # removing space start and end of the string and capitalize it.\n",
    "        street_name = street_name.strip().capitalize()\n",
    "        # take only street_type from the street_name\n",
    "        street_type = street_type_re.search(street_name).group()\n",
    "        # capitalize street type\n",
    "        capitalized = street_type.capitalize()\n",
    "    # collecting errors\n",
    "    except : \n",
    "        street_type = \"_\"\n",
    "        cautions['street'][street_type].append((id_,street_name))\n",
    "        return street_name\n",
    "    # transform data if its street type is listed in 'to_fix' dictionary.\n",
    "    if street_type.lower() in to_fix.keys():\n",
    "        to_return= street_name.replace(street_type,to_fix[capitalized.lower()])\n",
    "    \n",
    "    # collecting suspicious errors\n",
    "    elif capitalized not in expected:\n",
    "        to_return = street_name.replace(street_type,capitalized)\n",
    "        cautions['street'][street_type].append((id_,street_name))\n",
    "    \n",
    "    else:\n",
    "        to_return= street_name.replace(street_type,capitalized)\n",
    "    \n",
    "    return to_return\n",
    "\n",
    "\n",
    "def audit_postcode(postcode, id_):\n",
    "    \"\"\"\n",
    "    Recording inappropriate postcode data in 'caution' dictionary and returns it corrected.\n",
    "    \"\"\"\n",
    "    \n",
    "    postcode = postcode.strip()\n",
    "    p = postcode_type_re.search(postcode)\n",
    "    if p:\n",
    "        to_return = p.group()\n",
    "    else:    \n",
    "        cautions['postcode'][id_]=postcode\n",
    "        to_return=postcode\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def audit_pos(lat,lon):\n",
    "    \"\"\"\n",
    "    Recording inappropriate position data in 'caution' dictionary and returns it in a list of float.\n",
    "    \n",
    "    The valid range of latitude in degrees is -90 and +90 for the southern and northern hemisphere respectively.\n",
    "        Longitude is in the range -180 and +180 specifying the east-west position.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        lat = element['lat']\n",
    "        lon = element['lon']\n",
    "                \n",
    "        lat = float(lat)\n",
    "        lon = float(lon)\n",
    "\n",
    "        if not -90<=lat<=90 or not -180<=lon<=180:\n",
    "            cautions['pos'].append([lat, lon])\n",
    "\n",
    "    except ValueError:\n",
    "        cautions['pos'].append([lat, lon])\n",
    "    \n",
    "    return [lat,lon]\n",
    "\n",
    "\n",
    "def audit_height(height,id_):\n",
    "    \"\"\"\n",
    "    Recording inappropriate height data in 'caution' dictionary and returns it in float and in feet.\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(height, float):\n",
    "        return height\n",
    "    try :\n",
    "        # remove foot symbol(') from the data\n",
    "        if height.endswith(\"'\"):\n",
    "            height = float(height.replace(\"'\",\"\"))\n",
    "            \n",
    "        # remove inch symbol(\"\") from the data\n",
    "        elif height.endswith('\"'):\n",
    "            height = float(height.replace('\"',''))/12\n",
    "            \n",
    "        height = float(height)\n",
    "\n",
    "        if height<=4 and element['tag_type']=='node':\n",
    "            cautions['height'][id_]=height\n",
    "        else: heights.append(height)\n",
    "    except ValueError:\n",
    "        cautions['height'][id_]=element['height']\n",
    "    \n",
    "    return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def auditing_data(element):\n",
    "    \"\"\"\n",
    "    Execute audit data of five attributes of element: street, postcode, timestamp, latitude, longtitude, and height \n",
    "    for an input element.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:     id_ = element['id']\n",
    "    except : cautions['id'].append(element)\n",
    "    \n",
    "    if 'addr' in element.keys():\n",
    "        \n",
    "        ## Street name auditing     \n",
    "        try : \n",
    "            street_name = element['addr']['street']\n",
    "            audit_street(street_name,id_)\n",
    "        except : pass\n",
    "\n",
    "        ## postcode\n",
    "        try:\n",
    "            postcode = element['addr']['postcode']\n",
    "            if postcode:\n",
    "                audit_postcode(postcode,id_)\n",
    "        except:pass    \n",
    "    \n",
    "    ### timestamp\n",
    "    try:\n",
    "        str_time = element['timestamp']\n",
    "        audit_timestamp(str_time)\n",
    "    except: pass\n",
    "    \n",
    "    ### latitude and longtitude\n",
    "    try:\n",
    "        lat = element['lat']\n",
    "        lon = element['lon']\n",
    "        audit_pos(lat, lon)\n",
    "    except: pass\n",
    "    \n",
    "    ### height: range, numeric?\n",
    "    try:\n",
    "        height = element['height']\n",
    "        audit_height(height,id_)\n",
    "    except : pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Running Data Audit\n",
    "\n",
    "# a collection for suspicious error data\n",
    "cautions = dict(street=defaultdict(list)\n",
    "               , postcode=defaultdict(dict)\n",
    "               , timestamp=[]\n",
    "               , pos=[]\n",
    "               , height={}\n",
    "               , id =[]) \n",
    "\n",
    "# stores values of heights to expore distribution of heights values\n",
    "heights=[]\n",
    "\n",
    "# executing audit for every element in the dataset.\n",
    "for key, element in data.items():\n",
    "    if element!={}:\n",
    "        auditing_data(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "[('2563147351', 'Avenue p')]\n",
      "k\n",
      "[('2563756182', 'Avenue k')]\n",
      "_\n",
      "[('305556622', {}), ('295802801', {}), ('367684623', {}), ('368051665', {})]\n",
      "southwest\n",
      "[('2562041516', 'Prospect park southwest')]\n"
     ]
    }
   ],
   "source": [
    "######################AUDITING RESULT ##############################################\n",
    "\n",
    "### Checking Street data\n",
    "st = cautions['street']\n",
    "\n",
    "for key, val in st.items():\n",
    "    print key\n",
    "    print val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'addr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ee7f285290d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#>> correct [('3580782407', 'West 80th Street NYC 10024')]: cut the postcode in the street field to postcode field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'3580782407'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'3580782407'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'addr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'postcode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'10024'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'3580782407'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'addr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'street'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'West 80th Street'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'addr'"
     ]
    }
   ],
   "source": [
    "#>> correct [('3580782407', 'West 80th Street NYC 10024')]: cut the postcode in the street field to postcode field\n",
    "print data['3580782407']\n",
    "data['3580782407']['addr']['postcode'] = '10024'\n",
    "data['3580782407']['addr']['street'] = 'West 80th Street'\n",
    "print\n",
    "print data['3580782407']\n",
    "\n",
    "#>> adding newly discovered street type in the 'expected' list.\n",
    "expected.extend(['Path','Mall', 'Mews','Village','Slip', 'Ridge', 'Heights','Driveway', 'Roadbed', 'Center'\n",
    "                 ,'Expressway','Rockaways'])\n",
    "\n",
    "#>> add pairs to correct street type in the to_fix dictionary.\n",
    "to_fix['aveneu'] = 'Avenue'\n",
    "to_fix['pkwy'] = 'Parkway'\n",
    "to_fix['dr.'] = 'Drive'\n",
    "to_fix['ave.'] = 'Avenue'\n",
    "to_fix['streeet'] = 'Street'\n",
    "to_fix['st.'] = 'Street'\n",
    "to_fix['blvd.']='Building'\n",
    "to_fix['hwy'] = \"Highway\"\n",
    "to_fix['blv.'] = 'Boulevard'\n",
    "to_fix['dr'] = 'Drive'\n",
    "to_fix['blvd'] = 'Boulevard'\n",
    "to_fix['aveneu'] = 'Avenue'\n",
    "to_fix['pl'] = 'Place'\n",
    "to_fix['tirnpike']='Turnpike'\n",
    "to_fix['ct']='Court'\n",
    "to_fix['tunpike']='Turnpike'\n",
    "to_fix['pky'] = 'Parkway'\n",
    "\n",
    "print\n",
    "print to_fix.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'dict'>, {})\n"
     ]
    }
   ],
   "source": [
    "### checking postcode data\n",
    "print cautions['postcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'addr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-15c51b9ccd7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#>> removing data which doesn't comform to postcode format.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcautions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'postcode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'addr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'postcode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'addr'"
     ]
    }
   ],
   "source": [
    "#>> moving phone data into phone section from postcode\n",
    "data['3810255154']['phone'] = cautions['postcode']['3810255154']\n",
    "print data['3810255154']['phone']\n",
    "\n",
    "#>> removing data which doesn't comform to postcode format.\n",
    "for i in cautions['postcode'].keys():\n",
    "    data[i]['addr']['postcode']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "### checking timestamp error data\n",
    "print cautions['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "10.0\n",
      "6.0\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "### checking height error data\n",
    "\n",
    "h = cautions['height']\n",
    "    \n",
    "print len(h), len(heights)\n",
    "\n",
    "print max(heights)\n",
    "print min(heights)\n",
    "\n",
    "print h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_height(height,id_):\n",
    "    \"\"\"\n",
    "    Modify 'audit_height' method to add regex for reshaping the height attribute in the same unit(feet).\n",
    "    \"\"\"\n",
    "\n",
    "    inch = ['\"', 'inch']\n",
    "    feet = ['ft', \"'\", 'feet']\n",
    "    meter = ['m', 'meter']\n",
    "    \n",
    "    if isinstance(height, float):\n",
    "        return height\n",
    "    \n",
    "    try:\n",
    "        ## inch\n",
    "        for i in inch:\n",
    "            if i in height:\n",
    "                height = float(height.replace(i, \"\").strip())/12\n",
    "                break\n",
    "        ## meter\n",
    "\n",
    "        for m in meter:\n",
    "            if m in height:\n",
    "                height = float(height.replace(m, \"\").strip()) * 3.28084\n",
    "                break\n",
    "\n",
    "        ## feet\n",
    "        for f in feet:\n",
    "            if f in height:\n",
    "                height = float(height.replace(f, \"\").strip())\n",
    "                break\n",
    "\n",
    "        if not isinstance(height, float):\n",
    "            height = float(height.strip())\n",
    "\n",
    "        if height<=4 and element['tag_type']=='node':\n",
    "            cautions['height'][id_]= height\n",
    "        else: heights.append(height)\n",
    "\n",
    "    except:            \n",
    "        cautions['height'][id_] = height\n",
    "\n",
    "    return height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking error data latitude and longtitude\n",
    "\n",
    "cautions['pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Data and Store Data In JSON File\n",
    "\n",
    "Here, I reshaped the data and saved the data in JSON format to import it to the MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# to save datetime object in json: referred> https://stackoverflow.com/questions/11875770/how-to-overcome-datetime-datetime-not-json-serializable-in-python\n",
    "\n",
    "\n",
    "### processing data in an input osm file and save it in both JSON format and a list( 'data')\n",
    "\n",
    "json_file_name_out = \"%s.json\" %(osm_file_name)\n",
    "\n",
    "cautions = dict(street=defaultdict(list)\n",
    "               , postcode=[]\n",
    "               , id=[]\n",
    "               , timestamp=[]\n",
    "               , pos=[]\n",
    "               , height={}) \n",
    "\n",
    "def osm_to_json(data, json_file_name_out):\n",
    "    \"\"\"\n",
    "    Refine data from an original osm file and save it in both JSON format and a list( 'data')\n",
    "    \n",
    "    \"\"\"\n",
    "    problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "    CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\", 'created_by']\n",
    "    \n",
    "    with open(json_file_name_out,'w') as output:\n",
    "        i=0\n",
    "        for _id, element in data.items():\n",
    "            ele = {'created':{}}\n",
    "\n",
    "            for key, val in element.items():\n",
    "\n",
    "                if key in tag_attrib_to_exclude or val == None:\n",
    "                    continue\n",
    "\n",
    "                if key== 'addr':\n",
    "                    try:\n",
    "                        addr = ele[key]\n",
    "                    except KeyError:\n",
    "                        ele[key]={}\n",
    "\n",
    "                    for k, v in element[key].items():\n",
    "                        if v=={} or v==None:\n",
    "                            continue\n",
    "\n",
    "                        if k =='postcode':\n",
    "                            ele[key][k] = audit_postcode(v,_id)\n",
    "\n",
    "                        elif k == 'street':\n",
    "                            if v!='':\n",
    "                                ele[key][k] = audit_street(v,_id)\n",
    "                        else :\n",
    "                            ele[key][k]=v              \n",
    "\n",
    "                elif key == 'lat':\n",
    "                    ele['pos'] = audit_pos(val, element['lon'])\n",
    "                elif key =='height':\n",
    "                    ele[key] = audit_height(val,_id)\n",
    "                elif key in CREATED:\n",
    "                    if key =='timestamp': val = audit_timestamp(val)\n",
    "                    ele['created'][key]=val\n",
    "                else:\n",
    "                    ele[key] = val\n",
    "\n",
    "            ### save the element dictionary in a JSON file\n",
    "            output.write(json.dumps(ele, default = json_util.default)+'\\n')\n",
    "\n",
    "            i+=1\n",
    "            if i%1000000==1: print i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osm_to_json(data, json_file_name_out)\n",
    "\n",
    "### reviewing suspicious error data: street\n",
    "for key, val in cautions['street'].items():\n",
    "    print key\n",
    "    pprint.pprint(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### reviewing suspicious error data: others\n",
    "print cautions['postcode']\n",
    "print cautions['timestamp']\n",
    "print cautions['id']\n",
    "print cautions['pos']\n",
    "print cautions['height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Exploring Data in MongoDB\n",
    "\n",
    "In MongoDB Shell, one could import the data in JSON file created just before, typing command below.\n",
    "\n",
    "\"mongoimport --db p3(:db name) --collection new_york(:collection name) --file datafile.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Connecting to my MongoDB db, 'p3'\n",
    "\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "\n",
    "db = client.p3\n",
    "collection = 'new_york'\n",
    "#collection = 'sample_ny'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING INDEXES\n",
    "\n",
    "Here created indexes for fields which are used for queries to improve speed performance. Especially, for 'pos' field, used GEO2D INDEX to make it possible to find near specified locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a 2d Index: https://docs.mongodb.com/v3.0/tutorial/build-a-2d-index/\n",
    "#### in pyMongo    : http://api.mongodb.com/python/1.7/examples/geo.html\n",
    "\n",
    "if True:\n",
    "    \n",
    "    db[collection].create_index([('id',1)])\n",
    "    db[collection].create_index([('timestamp',1)])\n",
    "    db[collection].create_index([('name',1)])\n",
    "    db[collection].create_index([('address',1)])\n",
    "    \n",
    "    from pymongo import GEO2D\n",
    "\n",
    "    db[collection].create_index([('pos',GEO2D)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 0.1: number of unique users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2699"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db[collection].find(query).distinct('created.uid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 0.2: number of amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11809"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query ={'amenity':{'$ne': None}}\n",
    "db[collection].find(query).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1:  Top 10 users who uploaded the data most often and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'Rub21_nycbuildings', u'frequency': 1630934}\n",
      "{u'_id': u'ingalls_nycbuildings', u'frequency': 312022}\n",
      "{u'_id': u'woodpeck_fixbot', u'frequency': 216254}\n",
      "{u'_id': u'ediyes_nycbuildings', u'frequency': 90610}\n",
      "{u'_id': u'lxbarth_nycbuildings', u'frequency': 78243}\n",
      "{u'_id': u'NJDataUploads', u'frequency': 75882}\n",
      "{u'_id': u'ingalls', u'frequency': 64129}\n",
      "{u'_id': u'CoreyFarwell', u'frequency': 57218}\n",
      "{u'_id': u'smlevine', u'frequency': 52717}\n",
      "{u'_id': u'celosia_nycbuildings', u'frequency': 44876}\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {'$group':{'_id': '$created.user', 'frequency': {'$sum':1} }}\n",
    "    , {'$sort': {'frequency':-1}}    \n",
    "    , {'$limit':10}    \n",
    "    ]\n",
    "\n",
    "result = db[collection].aggregate(pipeline)\n",
    "\n",
    "for e in result:\n",
    "    pprint.pprint(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2:  The number of data uploaded by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': 2007, u'frequency': 1911}\n",
      "{u'_id': 2008, u'frequency': 7496}\n",
      "{u'_id': 2009, u'frequency': 341954}\n",
      "{u'_id': 2010, u'frequency': 61920}\n",
      "{u'_id': 2011, u'frequency': 33846}\n",
      "{u'_id': 2012, u'frequency': 61844}\n",
      "{u'_id': 2013, u'frequency': 1349442}\n",
      "{u'_id': 2014, u'frequency': 1263142}\n",
      "{u'_id': 2015, u'frequency': 203789}\n",
      "{u'_id': 2016, u'frequency': 124226}\n"
     ]
    }
   ],
   "source": [
    "### run query\n",
    "\n",
    "# ref : https://docs.mongodb.com/v3.0/reference/operator/aggregation/month/\n",
    "pipeline = [\n",
    "            {'$project': {'year': { '$year': \"$timestamp\"}}}\n",
    "             ,{'$group': {'_id':'$year', 'frequency': {'$sum': 1} }}\n",
    "             ,{'$sort': {'_id':1}} \n",
    "        ]    \n",
    "\n",
    "result = db[collection].aggregate(pipeline)\n",
    "\n",
    "for r in result:\n",
    "    pprint.pprint(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3:  Finding the Five Nearest locations from 'AJ's Pizza'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AJ's Pizza 's location:  [40.9709906, -74.2874519]\n"
     ]
    }
   ],
   "source": [
    "## looking for position of \"AJ's Pizza\".\n",
    "name = \"AJ's Pizza\"\n",
    "pipeline ={'$query': {'name':name}\n",
    "        ,'$project':{'name':'$name', 'pos':'$pos'}\n",
    "       }\n",
    "result = db[collection].find(pipeline)\n",
    "\n",
    "for r in result:\n",
    "    \n",
    "    position = r['pos']\n",
    "    \n",
    "print\n",
    "print name,\"'s location: \", position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{u'_id': ObjectId('5750679e41b59731cae4de3d'),\n",
      " u'created': {u'changeset': u'33558948',\n",
      "              u'uid': u'119748',\n",
      "              u'user': u'peace2',\n",
      "              u'version': u'1'},\n",
      " u'id': u'3712775825',\n",
      " u'lon': u'-74.0471541',\n",
      " u'name': u'',\n",
      " u'pos': [40.795324, -74.0471541],\n",
      " u'tag_type': u'node',\n",
      " u'timestamp': datetime.datetime(2015, 8, 24, 22, 2, 27),\n",
      " u'tourism': u'viewpoint'}\n",
      "\n",
      "{u'_id': ObjectId('5750673e41b59731cac73025'),\n",
      " u'created': {u'changeset': u'20598157',\n",
      "              u'uid': u'1938128',\n",
      "              u'user': u'sraposa17',\n",
      "              u'version': u'1'},\n",
      " u'id': u'2675006619',\n",
      " u'lon': u'-74.2225062',\n",
      " u'name': u'#R00T_QUAD',\n",
      " u'natural': u'tree',\n",
      " u'pos': [40.8020167, -74.2225062],\n",
      " u'tag_type': u'node',\n",
      " u'timestamp': datetime.datetime(2014, 2, 16, 16, 13, 39)}\n",
      "\n",
      "{u'_id': ObjectId('5750674c41b59731cacebff1'),\n",
      " u'addr': {u'city': u'Garwood',\n",
      "           u'housenumber': u'700',\n",
      "           u'postcode': u'07027',\n",
      "           u'state': u'NJ',\n",
      "           u'street': u'North Avenue'},\n",
      " u'amenity': u'cafe',\n",
      " u'created': {u'changeset': u'35340495',\n",
      "              u'uid': u'3386894',\n",
      "              u'user': u'mhe500',\n",
      "              u'version': u'1'},\n",
      " u'cuisine': u'sandwich',\n",
      " u'id': u'3838252749',\n",
      " u'internet_access': u'yes',\n",
      " u'lon': u'-74.330757',\n",
      " u'name': u'&Grain',\n",
      " u'phone': u'+1 908 232 2233',\n",
      " u'pos': [40.652768, -74.330757],\n",
      " u'tag_type': u'node',\n",
      " u'timestamp': datetime.datetime(2015, 11, 16, 0, 35, 10)}\n",
      "\n",
      "{u'_id': ObjectId('5750679e41b59731cae4f6e0'),\n",
      " u'addr': {u'city': u'New York',\n",
      "           u'housenumber': u'440',\n",
      "           u'postcode': u'10016',\n",
      "           u'street': u'East 29th Street'},\n",
      " u'amenity': u'fast_food',\n",
      " u'created': {u'changeset': u'18670031',\n",
      "              u'uid': u'1721804',\n",
      "              u'user': u'celosia',\n",
      "              u'version': u'1'},\n",
      " u'id': u'2517052271',\n",
      " u'lon': u'-73.9742908',\n",
      " u'name': u\"'wichcraft\",\n",
      " u'phone': u'+1 212 780-0577',\n",
      " u'pos': [40.7396985, -73.9742908],\n",
      " u'tag_type': u'node',\n",
      " u'timestamp': datetime.datetime(2013, 11, 2, 5, 51, 57),\n",
      " u'website': u'http://wichcraftnyc.com/'}\n",
      "\n",
      "{u'_id': ObjectId('5750672241b59731cab8ed01'),\n",
      " u'access': u'public',\n",
      " u'amenity': u'toilets',\n",
      " u'created': {u'changeset': u'22879596',\n",
      "              u'uid': u'296103',\n",
      "              u'user': u'Laezo6eu',\n",
      "              u'version': u'1'},\n",
      " u'id': u'2912011680',\n",
      " u'lon': u'-73.4992778',\n",
      " u'name': u'(seasonal)',\n",
      " u'operator': u'Stamford city parks',\n",
      " u'pos': [41.0473478, -73.4992778],\n",
      " u'tag_type': u'node',\n",
      " u'timestamp': datetime.datetime(2014, 6, 11, 21, 24, 10)}\n"
     ]
    }
   ],
   "source": [
    "### Query a 2d Index: https://docs.mongodb.com/manual/tutorial/query-a-2d-index/\n",
    "\n",
    "query = {'pos':{'$near':position}, 'name':{'$ne':None}, 'tag_type':'node', 'pos':{'$ne':position}}\n",
    "\n",
    "result = db[collection].find(query).limit(5)\n",
    "\n",
    "for doc in result:\n",
    "    print\n",
    "    pprint.pprint(doc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
